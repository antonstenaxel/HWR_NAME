{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {'Alef': 0,\n",
    " 'Ayin': 1,\n",
    " 'Bet': 2,\n",
    " 'Dalet': 3,\n",
    " 'Gimel': 4,\n",
    " 'He': 5,\n",
    " 'Het': 6,\n",
    " 'Kaf': 7,\n",
    " 'Kaf-final': 8,\n",
    " 'Lamed': 9,\n",
    " 'Mem': 10,\n",
    " 'Mem-medial': 11,\n",
    " 'Nun-final': 12,\n",
    " 'Nun-medial': 13,\n",
    " 'Pe': 14,\n",
    " 'Pe-final': 15,\n",
    " 'Qof': 16,\n",
    " 'Resh': 17,\n",
    " 'Samekh': 18,\n",
    " 'Shin': 19,\n",
    " 'Taw': 20,\n",
    " 'Tet': 21,\n",
    " 'Tsadi-final': 22,\n",
    " 'Tsadi-medial': 23,\n",
    " 'Waw': 24,\n",
    " 'Yod': 25,\n",
    " 'Zayin': 26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, train_test_split=0.7):\n",
    "    n_datapoints = 0; \n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        n_datapoints +=1\n",
    "        \n",
    "    \n",
    "    flag = 1; \n",
    "    \n",
    "    count = 0\n",
    "    for filename in os.listdir(path):\n",
    "        img = np.double(cv2.imread(path+\"/\"+filename,0));\n",
    "        \n",
    "        if(flag == 1):\n",
    "            \n",
    "            shape = np.shape(img);\n",
    "            \n",
    "            all_images = np.zeros([n_datapoints, shape[1], shape[0]])\n",
    "            all_labels = np.zeros([n_datapoints])\n",
    "  \n",
    "            flag = 0; \n",
    "     \n",
    "        \n",
    "        label = dic[filename.split(\"_\")[0]]\n",
    "        \n",
    "        all_images[count] = img\n",
    "        all_labels[count] = label\n",
    "        \n",
    "        \n",
    "        count += 1 \n",
    "        \n",
    "        \n",
    "    n_training_points = int(train_test_split * n_datapoints)\n",
    "    \n",
    "    perm = np.random.permutation(n_datapoints)\n",
    "    train_indices = perm[:n_training_points]\n",
    "    test_indices = perm[n_training_points:]\n",
    "    \n",
    "    x_train = all_images[train_indices]\n",
    "    y_train = all_labels[train_indices]\n",
    "    \n",
    "    x_test = all_images[test_indices]\n",
    "    y_test = all_labels[test_indices]\n",
    "    \n",
    "        \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data(\"/Users/Karlsson/Documents/Skola/Handwriting_Recognition/monkbrill_same_size/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x183464b518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADahJREFUeJzt3V2MVPUZx/Hfw5tvYFZhoSCsSxvS\nYJoUzYTU2DQ2jY02jciFRC4ampDiRUms6UWJN/WmhpgqNcaYYCWisbYmSsWIViRGa1KNoyGVFqrE\nrGUFYRA3gC8huzy92EOzxZ3/GWbOnDP2+X6Szcyc55w5D8P+9szM/8z8zd0FIJ4pVTcAoBqEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNPK3NmcOXN8cHCwzF0CoQwNDeno0aPWyrodhd/Mrpd0\nn6Spkn7v7htT6w8ODqper3eySwAJtVqt5XXbftpvZlMlPSDpBklXSFptZle0e38AytXJa/7lkva7\n+/vufkrSHyWtKKYtAN3WSfgvk3Rgwu3hbNn/MLN1ZlY3s3qj0ehgdwCK1En4J3tT4UufD3b3ze5e\nc/daf39/B7sDUKROwj8sadGE2wslHeysHQBl6ST8b0paYmaLzWyGpFskbS+mLQDd1vZQn7uPmtl6\nSX/R+FDfFnf/R2GdAeiqjsb53X2HpB0F9QKgRJzeCwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4g\nKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFAdzdJrZkOSTkgakzTq7rUimgLQfR2FP/N9dz9awP0AKBFP+4Gg\nOg2/S3rRzN4ys3VFNASgHJ0+7b/G3Q+a2VxJO81sn7u/OnGF7I/COkkaGBjocHcAitLRkd/dD2aX\nRyRtk7R8knU2u3vN3Wv9/f2d7A5AgdoOv5ldZGazzlyX9ENJe4pqDEB3dfK0f56kbWZ25n7+4O4v\nFNIVgK5rO/zu/r6kb5/LNiMjI9q2bVvT+uDgYHL7KVOaP1GZPXt2ctsFCxa0fd/A/yN+44GgCD8Q\nFOEHgiL8QFCEHwiK8ANBFfGpvpb19fVp5cqVZe4SQBMc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4g\nKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nIKjc8JvZFjM7YmZ7Jiy71Mx2mtl72eUl3W0TQNFaOfI/Iun6s5ZtkLTL3ZdI2pXdBvAVkht+d39V\n0rGzFq+QtDW7vlXSTQX3BaDL2n3NP8/dD0lSdjm3uJYAlKHrb/iZ2Tozq5tZvdFodHt3AFrUbvgP\nm9l8ScoujzRb0d03u3vN3Wv9/f1t7g5A0doN/3ZJa7LrayQ9U0w7AMrSylDfE5L+JumbZjZsZmsl\nbZR0nZm9J+m67DaAr5BpeSu4++ompR8U3AuAEnGGHxAU4QeCIvxAUIQfCIrwA0ERfiCo3KE+oFu+\n+OKLZH3fvn3J+scff5ysj46ONq2df/75yW2XLl2arOedrWpmyXov4MgPBEX4gaAIPxAU4QeCIvxA\nUIQfCIrwA0Exzl+A06dPJ+u7d+9O1p977rlk/fjx48n69OnTm9ZmzpyZ3Hbt2rXJ+rx585L1kZGR\nZH3Tpk1Na/fff39H9+3uyXon+vr6kvVdu3Yl61dddVWR7XQFR34gKMIPBEX4gaAIPxAU4QeCIvxA\nUIQfCCrMOP/Y2FiynjcW//LLLzetPfDAA8lth4aGkvUqzZgxI1m/9dZbk/W77rorWb/nnnua1vLO\nj6jS1VdfnawPDAyU1En3cOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByx/nNbIukH0s64u7fypbd\nKelnkhrZane4+45uNXlGalz4008/TW67fv36ZP2xxx5L1rv52fEq7diR/m/L+376Dz74IFnv1bH8\nyy+/PFnPO39hzpw5RbZTiVaO/I9Iun6S5ZvcfVn20/XgAyhWbvjd/VVJx0roBUCJOnnNv97M/m5m\nW8zsksI6AlCKdsP/oKRvSFom6ZCkpidwm9k6M6ubWb3RaDRbDUDJ2gq/ux929zF3Py3pIUnLE+tu\ndveau9fy3jwCUJ62wm9m8yfcXClpTzHtAChLK0N9T0i6VtIcMxuW9GtJ15rZMkkuaUhS+nOfAHpO\nbvjdffUkix/uQi+5Y8Kp74DPG5f95JNPkvVOxvHz5mLv5XMEUt9TIEmvvPJKsn7eeecV2U5pTp48\nmayPjo6W1El1OMMPCIrwA0ERfiAowg8ERfiBoAg/EFRPfXX3sWPpzw/t3bu3ae3zzz9PbtvpcFxq\n+xtvvDG57e23356s503RvX379mQ99bgdPXo0uW3evztv+DXvce9VF154YbKe93XrixcvTtZnz559\nri2VjiM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTVU+P8eWPGn332WdNa3jj+tGnpf+qpU6eS9dR4\n+EsvvZTcdsOGDcn63Xff3VH9+PHjTWsvvPBCctvXX389WX/22WeT9f379yfrverAgQPJ+s0335ys\nz5o1K1lfunRpsn7bbbc1ra1cuTK57QUXXJCst4ojPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1VPj\n/HPnzk3W165d27SWN47/9NNPJ+t54/wpeV9fPXXq1LbvuxUXX3xx09qqVauS2+bVN27cmKzv27cv\nWU99Nfjzzz+f3PbDDz9M1vfsqW6umBMnTiTreec/fPTRR0W20xaO/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QlLXwffWLJD0q6WuSTkva7O73mdmlkv4kaVDSkKRV7p6cB7tWq3m9Xi+g7XM3MjKSrL/7\n7rvJ+tjYWNPaokWLktsuWLAgWZ8yhb/Bk8mbM2B4eDhZzzsHoRN555UsWbIkWV+4cGHTWt53U6TU\najXV6/WW7qCV37pRSb9096WSviPp52Z2haQNkna5+xJJu7LbAL4icsPv7ofc/e3s+glJeyVdJmmF\npK3Zalsl3dStJgEU75yeb5rZoKQrJb0haZ67H5LG/0BISp+bC6CntBx+M5sp6SlJv3D35l8a9+Xt\n1plZ3czqjUajnR4BdEFL4Tez6RoP/uPufuYTMofNbH5Wny/pyGTbuvtmd6+5e62/v7+IngEUIDf8\nNv7W48OS9rr7vRNK2yWtya6vkfRM8e0B6JZWPtJ7jaSfSHrHzHZny+6QtFHSk2a2VtK/JaW/67hi\nfX19yfry5ctL6gStyhsCHRgY6KgeXW743f01Sc3GDX9QbDsAysLZJUBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgcsNvZovM7GUz22tm/zCz27Lld5rZh2a2\nO/v5UffbBVCUaS2sMyrpl+7+tpnNkvSWme3Mapvc/bfdaw9At+SG390PSTqUXT9hZnslXdbtxgB0\n1zm95jezQUlXSnojW7TezP5uZlvM7JIm26wzs7qZ1RuNRkfNAihOy+E3s5mSnpL0C3c/LulBSd+Q\ntEzjzwzumWw7d9/s7jV3r/X39xfQMoAitBR+M5uu8eA/7u5PS5K7H3b3MXc/LekhScu71yaAorXy\nbr9JeljSXne/d8Ly+RNWWylpT/HtAeiWVt7tv0bSTyS9Y2a7s2V3SFptZsskuaQhSbd2pUMAXdHK\nu/2vSbJJSjuKbwdAWTjDDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E\nRfiBoAg/EJS5e3k7M2tI+mDCojmSjpbWwLnp1d56tS+J3tpVZG+Xu3tL35dXavi/tHOzurvXKmsg\noVd769W+JHprV1W98bQfCIrwA0FVHf7NFe8/pVd769W+JHprVyW9VfqaH0B1qj7yA6hIJeE3s+vN\n7F9mtt/MNlTRQzNmNmRm72QzD9cr7mWLmR0xsz0Tll1qZjvN7L3sctJp0irqrSdmbk7MLF3pY9dr\nM16X/rTfzKZKelfSdZKGJb0pabW7/7PURpowsyFJNXevfEzYzL4n6aSkR939W9myuyUdc/eN2R/O\nS9z9Vz3S252STlY9c3M2ocz8iTNLS7pJ0k9V4WOX6GuVKnjcqjjyL5e0393fd/dTkv4oaUUFffQ8\nd39V0rGzFq+QtDW7vlXjvzyla9JbT3D3Q+7+dnb9hKQzM0tX+tgl+qpEFeG/TNKBCbeH1VtTfruk\nF83sLTNbV3Uzk5iXTZt+Zvr0uRX3c7bcmZvLdNbM0j3z2LUz43XRqgj/ZLP/9NKQwzXufpWkGyT9\nPHt6i9a0NHNzWSaZWbontDvjddGqCP+wpEUTbi+UdLCCPibl7gezyyOStqn3Zh8+fGaS1OzySMX9\n/Fcvzdw82czS6oHHrpdmvK4i/G9KWmJmi81shqRbJG2voI8vMbOLsjdiZGYXSfqhem/24e2S1mTX\n10h6psJe/kevzNzcbGZpVfzY9dqM15Wc5JMNZfxO0lRJW9z9N6U3MQkz+7rGj/bS+CSmf6iyNzN7\nQtK1Gv/U12FJv5b0Z0lPShqQ9G9JN7t76W+8NentWo0/df3vzM1nXmOX3Nt3Jf1V0juSTmeL79D4\n6+vKHrtEX6tVwePGGX5AUJzhBwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqP8AbZ8EbZoRStIA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183447f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 27\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3875, 28, 28, 1)\n",
      "3875 train samples\n",
      "1662 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3875 samples, validate on 1662 samples\n",
      "Epoch 1/12\n",
      "3875/3875 [==============================] - 12s 3ms/step - loss: 2.2387 - acc: 0.3706 - val_loss: 1.1714 - val_acc: 0.6799\n",
      "Epoch 2/12\n",
      "3875/3875 [==============================] - 11s 3ms/step - loss: 0.9486 - acc: 0.7453 - val_loss: 0.7776 - val_acc: 0.7930\n",
      "Epoch 3/12\n",
      "3875/3875 [==============================] - 12s 3ms/step - loss: 0.6923 - acc: 0.8119 - val_loss: 0.5329 - val_acc: 0.8694\n",
      "Epoch 4/12\n",
      "3875/3875 [==============================] - 12s 3ms/step - loss: 0.5432 - acc: 0.8449 - val_loss: 0.5565 - val_acc: 0.8526\n",
      "Epoch 5/12\n",
      "3875/3875 [==============================] - 12s 3ms/step - loss: 0.4943 - acc: 0.8627 - val_loss: 0.4423 - val_acc: 0.8833\n",
      "Epoch 6/12\n",
      "3875/3875 [==============================] - 13s 3ms/step - loss: 0.4042 - acc: 0.8841 - val_loss: 0.4523 - val_acc: 0.8761\n",
      "Epoch 7/12\n",
      "3875/3875 [==============================] - 12s 3ms/step - loss: 0.3571 - acc: 0.8919 - val_loss: 0.4107 - val_acc: 0.8875\n",
      "Epoch 8/12\n",
      "3875/3875 [==============================] - 13s 3ms/step - loss: 0.3237 - acc: 0.9022 - val_loss: 0.3741 - val_acc: 0.8983\n",
      "Epoch 9/12\n",
      "3875/3875 [==============================] - 13s 3ms/step - loss: 0.2872 - acc: 0.9099 - val_loss: 0.3708 - val_acc: 0.9019\n",
      "Epoch 10/12\n",
      "3875/3875 [==============================] - 14s 4ms/step - loss: 0.2643 - acc: 0.9148 - val_loss: 0.3512 - val_acc: 0.9007\n",
      "Epoch 11/12\n",
      "3875/3875 [==============================] - 14s 4ms/step - loss: 0.2318 - acc: 0.9221 - val_loss: 0.3551 - val_acc: 0.9019\n",
      "Epoch 12/12\n",
      "3875/3875 [==============================] - 15s 4ms/step - loss: 0.2130 - acc: 0.9319 - val_loss: 0.3748 - val_acc: 0.9116\n",
      "Test loss: 0.374780294267\n",
      "Test accuracy: 0.91155234614\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./baseline_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
